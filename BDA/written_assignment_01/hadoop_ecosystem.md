# Write briefly about the Hadoop Ecosystem.

- Hadoop Ecosystem is neither a programming language nor a service, it is a platform or framework which solves big data problems.
- You can consider it as a suite which encompasses a number of services (ingesting, storing, analyzing and maintaining) inside it. 
- Let us discuss and get a brief idea about how the services work individually and in collaboration.

- Below are the Hadoop components, that together form a Hadoop ecosystem, I will be covering each of them in this blog:

1) HDFS -> Hadoop Distributed File System
2) YARN -> Yet Another Resource Negotiator
3) MapReduce -> Data processing using programming
4) Spark -> In-memory Data Processing
5) PIG, HIVE-> Data Processing Services using Query (SQL-like)
6) HBase -> NoSQL Database
7) Mahout, Spark MLlib -> Machine Learning
8) Apache Drill -> SQL on Hadoop
9) Zookeeper -> Managing Cluster
10) Oozie -> Job Scheduling
11) Flume, Sqoop -> Data Ingesting Services
12) Solr & Lucene -> Searching & Indexing 
13) Ambari -> Provision, Monitor and Maintain cluster